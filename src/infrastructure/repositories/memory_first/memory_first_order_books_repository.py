# src/infrastructure/repositories/memory_first/memory_first_order_books_repository.py
import pandas as pd
import asyncio
import os
import json
from typing import List, Optional, Dict, Any, Tuple
from datetime import datetime, timedelta
from domain.entities.order_book import OrderBook
from ..interfaces.order_books_repository_interface import IOrderBooksRepository
from ..base.base_repository import MemoryFirstRepository
import logging

logger = logging.getLogger(__name__)

class MemoryFirstOrderBooksRepository(MemoryFirstRepository[OrderBook], IOrderBooksRepository):
    """
    –î–≤—É—Ö—É—Ä–æ–≤–Ω–µ–≤—ã–π —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —Å—Ç–∞–∫–∞–Ω–æ–≤ –æ—Ä–¥–µ—Ä–æ–≤ (–ü–û–¢–û–ö–û–í–´–ï –î–ê–ù–ù–´–ï):
    - –£—Ä–æ–≤–µ–Ω—å 1: DataFrame –≤ –ø–∞–º—è—Ç–∏ (–Ω–∞–∫–æ–ø–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö)
    - –£—Ä–æ–≤–µ–Ω—å 2: Parquet —Ñ–∞–π–ª—ã (–ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ –¥–∞–º–ø—ã)
    
    –ü—Ä–∏–Ω—Ü–∏–ø—ã –ø–æ—Ç–æ–∫–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö:
    - –ù–∞–∫–æ–ø–ª–µ–Ω–∏–µ –≤ –ø–∞–º—è—Ç–∏ –¥–æ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è batch_size
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–º–ø—ã –≤ Parquet –∫–∞–∂–¥—ã–µ N –º–∏–Ω—É—Ç
    - –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
    - –í—ã—Å–æ–∫–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –∑–∞–ø–∏—Å–∏ (—Ç—ã—Å—è—á–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –≤ —Å–µ–∫—É–Ω–¥—É)
    """
    
    def __init__(self, persistent_provider=None, batch_size: int = 5000, 
                 dump_interval_minutes: int = 3, keep_last_n: int = 50000):
        super().__init__(persistent_provider)
        self.batch_size = batch_size
        self.dump_interval_minutes = dump_interval_minutes
        self.keep_last_n = keep_last_n
        self.parquet_dir = "data/order_books"
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è Parquet —Ñ–∞–π–ª–æ–≤
        os.makedirs(self.parquet_dir, exist_ok=True)
        
        self._initialize_dataframe()
        self._last_dump_time = datetime.now()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–æ–Ω–æ–≤—É—é –∑–∞–¥–∞—á—É –¥–ª—è –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏—Ö –¥–∞–º–ø–æ–≤
        asyncio.create_task(self._periodic_dump_task())
    
    def _get_dataframe_columns(self) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É DataFrame –¥–ª—è —Å—Ç–∞–∫–∞–Ω–æ–≤ –æ—Ä–¥–µ—Ä–æ–≤"""
        return [
            'symbol', 'timestamp', 'best_bid', 'best_ask', 'spread',
            'bid_volume', 'ask_volume', 'total_bids', 'total_asks',
            'bids_json', 'asks_json', 'created_at'
        ]
    
    def _get_id_column(self) -> str:
        """ID –∫–æ–ª–æ–Ω–∫–∞ –¥–ª—è —Å—Ç–∞–∫–∞–Ω–æ–≤ (—Å–æ—Å—Ç–∞–≤–Ω–æ–π –∫–ª—é—á symbol + timestamp)"""
        return 'timestamp'
    
    def _optimize_dataframe_dtypes(self):
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏"""
        if not self.df.empty:
            # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            self.df['symbol'] = self.df['symbol'].astype('category')
            self.df['timestamp'] = self.df['timestamp'].astype('int64')
            self.df['best_bid'] = self.df['best_bid'].astype('float64')
            self.df['best_ask'] = self.df['best_ask'].astype('float64')
            self.df['spread'] = self.df['spread'].astype('float64')
            self.df['bid_volume'] = self.df['bid_volume'].astype('float64')
            self.df['ask_volume'] = self.df['ask_volume'].astype('float64')
            self.df['total_bids'] = self.df['total_bids'].astype('int32')
            self.df['total_asks'] = self.df['total_asks'].astype('int32')
    
    def _entity_to_dict(self, order_book: OrderBook) -> Dict[str, Any]:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ OrderBook –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è DataFrame"""
        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        best_bid = order_book.bids[0][0] if order_book.bids else 0.0
        best_ask = order_book.asks[0][0] if order_book.asks else 0.0
        spread = best_ask - best_bid if best_bid > 0 and best_ask > 0 else 0.0
        
        # –í—ã—á–∏—Å–ª—è–µ–º –æ–±—ä–µ–º—ã
        bid_volume = sum(bid[1] for bid in order_book.bids) if order_book.bids else 0.0
        ask_volume = sum(ask[1] for ask in order_book.asks) if order_book.asks else 0.0
        
        return {
            'symbol': order_book.symbol,
            'timestamp': order_book.timestamp,
            'best_bid': best_bid,
            'best_ask': best_ask,
            'spread': spread,
            'bid_volume': bid_volume,
            'ask_volume': ask_volume,
            'total_bids': len(order_book.bids) if order_book.bids else 0,
            'total_asks': len(order_book.asks) if order_book.asks else 0,
            'bids_json': json.dumps(order_book.bids[:10]) if order_book.bids else '[]',  # –¢–æ–ø 10
            'asks_json': json.dumps(order_book.asks[:10]) if order_book.asks else '[]',  # –¢–æ–ø 10
            'created_at': datetime.now()
        }
    
    def _dict_to_entity(self, data: Dict[str, Any]) -> OrderBook:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è –∏–∑ DataFrame –≤ OrderBook"""
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º bids –∏ asks –∏–∑ JSON
        bids = json.loads(data['bids_json']) if data['bids_json'] else []
        asks = json.loads(data['asks_json']) if data['asks_json'] else []
        
        # –°–æ–∑–¥–∞–µ–º OrderBook –æ–±—ä–µ–∫—Ç
        order_book = OrderBook(
            symbol=data['symbol'],
            bids=bids,
            asks=asks,
            timestamp=data['timestamp']
        )
        
        return order_book
    
    def save(self, order_book: OrderBook) -> None:
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç–∞–∫–∞–Ω–∞ –≤ –ø–∞–º—è—Ç—å (–º–≥–Ω–æ–≤–µ–Ω–Ω–æ) + –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥–∞–º–ø
        """
        order_book_data = self._entity_to_dict(order_book)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ DataFrame
        if self.df.empty:
            self.df = pd.DataFrame([order_book_data])
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º pd.DataFrame.loc –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è FutureWarning —Å pd.concat
            new_index = len(self.df)
            self.df.loc[new_index] = order_book_data
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –¥–∞–º–ø–∞
        if len(self.df) >= self.batch_size:
            asyncio.create_task(self._dump_to_parquet())
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if len(self.df) > self.keep_last_n:
            self._clear_old_data()
    
    def get_by_id(self, order_book_id: int) -> Optional[OrderBook]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞–∫–∞–Ω –ø–æ timestamp"""
        mask = self.df['timestamp'] == order_book_id
        if not mask.any():
            return None
        
        row = self.df[mask].iloc[-1]  # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –µ—Å–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ
        return self._dict_to_entity(row.to_dict())
    
    def get_all(self) -> List[OrderBook]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö —Å—Ç–∞–∫–∞–Ω–æ–≤ –∏–∑ DataFrame"""
        return [self._dict_to_entity(row.to_dict()) for _, row in self.df.iterrows()]
    
    def get_latest_order_book(self, symbol: str) -> Optional[OrderBook]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å—Ç–∞–∫–∞–Ω –ø–æ —Å–∏–º–≤–æ–ª—É"""
        symbol_mask = self.df['symbol'] == symbol
        if not symbol_mask.any():
            return None
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ timestamp –∏ –±–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π
        symbol_df = self.df[symbol_mask].sort_values('timestamp')
        latest_row = symbol_df.iloc[-1]
        
        return self._dict_to_entity(latest_row.to_dict())
    
    def get_spread_history(self, symbol: str, limit: int = 100) -> List[float]:
        """–ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —Å–ø—Ä–µ–¥–æ–≤"""
        symbol_mask = self.df['symbol'] == symbol
        if not symbol_mask.any():
            return []
        
        symbol_df = self.df[symbol_mask].sort_values('timestamp').tail(limit)
        return symbol_df['spread'].tolist()
    
    def get_order_books_by_symbol(self, symbol: str, limit: int = 1000) -> List[OrderBook]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞–∫–∞–Ω—ã –ø–æ —Å–∏–º–≤–æ–ª—É —Å –ª–∏–º–∏—Ç–æ–º"""
        symbol_mask = self.df['symbol'] == symbol
        if not symbol_mask.any():
            return []
        
        symbol_df = self.df[symbol_mask].sort_values('timestamp').tail(limit)
        return [self._dict_to_entity(row.to_dict()) for _, row in symbol_df.iterrows()]
    
    def get_liquidity_history(self, symbol: str, limit: int = 100) -> List[Tuple[float, float]]:
        """–ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏ (bid_volume, ask_volume)"""
        symbol_mask = self.df['symbol'] == symbol
        if not symbol_mask.any():
            return []
        
        symbol_df = self.df[symbol_mask].sort_values('timestamp').tail(limit)
        return list(zip(symbol_df['bid_volume'].tolist(), symbol_df['ask_volume'].tolist()))
    
    def get_best_prices_history(self, symbol: str, limit: int = 100) -> List[Tuple[float, float]]:
        """–ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –ª—É—á—à–∏—Ö —Ü–µ–Ω (best_bid, best_ask)"""
        symbol_mask = self.df['symbol'] == symbol
        if not symbol_mask.any():
            return []
        
        symbol_df = self.df[symbol_mask].sort_values('timestamp').tail(limit)
        return list(zip(symbol_df['best_bid'].tolist(), symbol_df['best_ask'].tolist()))
    
    def get_last_n(self, n: int) -> List[OrderBook]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –∑–∞–ø–∏—Å–µ–π"""
        last_df = self.df.sort_values('timestamp').tail(n)
        return [self._dict_to_entity(row.to_dict()) for _, row in last_df.iterrows()]
    
    def get_by_time_range(self, start_time: datetime, end_time: datetime) -> List[OrderBook]:
        """–ü–æ–ª—É—á–∏—Ç—å –∑–∞–ø–∏—Å–∏ –∑–∞ –ø–µ—Ä–∏–æ–¥ –≤—Ä–µ–º–µ–Ω–∏"""
        start_ts = int(start_time.timestamp() * 1000)
        end_ts = int(end_time.timestamp() * 1000)
        
        time_mask = (self.df['timestamp'] >= start_ts) & (self.df['timestamp'] <= end_ts)
        time_df = self.df[time_mask].sort_values('timestamp')
        
        return [self._dict_to_entity(row.to_dict()) for _, row in time_df.iterrows()]
    
    async def dump_to_persistent(self, batch_size: int = 5000) -> int:
        """–°–±—Ä–æ—Å –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ Parquet —Ñ–∞–π–ª—ã"""
        return await self._dump_to_parquet()
    
    def clear_old_data(self, keep_last_n: int = 50000) -> int:
        """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ø–∞–º—è—Ç–∏"""
        return self._clear_old_data(keep_last_n)
    
    def get_memory_usage_mb(self) -> float:
        """–ü–æ–ª—É—á–∏—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –≤ –ú–ë"""
        if self.df.empty:
            return 0.0
        memory_usage = self.df.memory_usage(deep=True).sum()
        return memory_usage / (1024 * 1024)
    
    def delete_by_id(self, order_book_id: int) -> bool:
        """–£–¥–∞–ª–∏—Ç—å —Å—Ç–∞–∫–∞–Ω –ø–æ timestamp"""
        mask = self.df['timestamp'] == order_book_id
        if mask.any():
            self.df = self.df[~mask].reset_index(drop=True)
            return True
        return False
    
    async def _dump_to_parquet(self) -> int:
        """–°–±—Ä–æ—Å –¥–∞–Ω–Ω—ã—Ö –≤ Parquet —Ñ–∞–π–ª"""
        if self.df.empty:
            return 0
        
        try:
            # –°–æ–∑–¥–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞ —Å —Ç–µ–∫—É—â–µ–π –¥–∞—Ç–æ–π
            filename = f"order_books_{datetime.now().strftime('%Y%m%d_%H%M%S')}.parquet"
            filepath = os.path.join(self.parquet_dir, filename)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Parquet
            self.df.to_parquet(filepath, compression='snappy', index=False)
            
            dumped_count = len(self.df)
            logger.info(f"‚úÖ Dumped {dumped_count} order books to {filepath}")
            
            # –û—á–∏—â–∞–µ–º DataFrame –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –¥–∞–º–ø–∞
            self.df = pd.DataFrame(columns=self._get_dataframe_columns())
            self._optimize_dataframe_dtypes()
            
            self._last_dump_time = datetime.now()
            return dumped_count
            
        except Exception as e:
            logger.error(f"‚ùå Error dumping order books to Parquet: {e}")
            return 0
    
    def _clear_old_data(self, keep_last_n: int = None) -> int:
        """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ø–∞–º—è—Ç–∏"""
        if keep_last_n is None:
            keep_last_n = self.keep_last_n
        
        if len(self.df) <= keep_last_n:
            return 0
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ timestamp –∏ –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –∑–∞–ø–∏—Å–µ–π
        self.df = self.df.sort_values('timestamp').tail(keep_last_n).reset_index(drop=True)
        
        removed_count = len(self.df) - keep_last_n
        logger.info(f"üßπ Cleared {removed_count} old order books from memory")
        
        return removed_count
    
    async def _periodic_dump_task(self):
        """–§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –¥–ª—è –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏—Ö –¥–∞–º–ø–æ–≤"""
        while True:
            try:
                await asyncio.sleep(self.dump_interval_minutes * 60)  # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å–µ–∫—É–Ω–¥—ã
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–µ–Ω –ª–∏ –¥–∞–º–ø
                time_since_last_dump = datetime.now() - self._last_dump_time
                if time_since_last_dump.total_seconds() >= self.dump_interval_minutes * 60:
                    if not self.df.empty:
                        await self._dump_to_parquet()
                        
            except Exception as e:
                logger.error(f"‚ùå Error in periodic dump task: {e}")
                await asyncio.sleep(60)  # –ñ–¥–µ–º –º–∏–Ω—É—Ç—É –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–æ–º