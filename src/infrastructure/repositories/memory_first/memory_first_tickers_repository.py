# src/infrastructure/repositories/memory_first/memory_first_tickers_repository.py
import pandas as pd
import asyncio
import os
from typing import List, Optional, Dict, Any
from datetime import datetime, timedelta
from domain.entities.ticker import Ticker
from ..interfaces.tickers_repository_interface import ITickersRepository
from ..base.base_repository import MemoryFirstRepository
import logging

logger = logging.getLogger(__name__)

class MemoryFirstTickersRepository(MemoryFirstRepository[Ticker], ITickersRepository):
    """
    –î–≤—É—Ö—É—Ä–æ–≤–Ω–µ–≤—ã–π —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —Ç–∏–∫–µ—Ä–æ–≤ (–ü–û–¢–û–ö–û–í–´–ï –î–ê–ù–ù–´–ï):
    - –£—Ä–æ–≤–µ–Ω—å 1: DataFrame –≤ –ø–∞–º—è—Ç–∏ (–Ω–∞–∫–æ–ø–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö)
    - –£—Ä–æ–≤–µ–Ω—å 2: Parquet —Ñ–∞–π–ª—ã (–ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ –¥–∞–º–ø—ã)
    
    –ü—Ä–∏–Ω—Ü–∏–ø—ã –ø–æ—Ç–æ–∫–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö:
    - –ù–∞–∫–æ–ø–ª–µ–Ω–∏–µ –≤ –ø–∞–º—è—Ç–∏ –¥–æ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è batch_size
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–º–ø—ã –≤ Parquet –∫–∞–∂–¥—ã–µ N –º–∏–Ω—É—Ç
    - –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
    - –í—ã—Å–æ–∫–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –∑–∞–ø–∏—Å–∏ (–º–∏–ª–ª–∏–æ–Ω—ã —Ç–∏–∫–µ—Ä–æ–≤)
    """
    
    def __init__(self, persistent_provider=None, batch_size: int = 10000, 
                 dump_interval_minutes: int = 5, keep_last_n: int = 100000):
        super().__init__(persistent_provider)
        self.batch_size = batch_size
        self.dump_interval_minutes = dump_interval_minutes
        self.keep_last_n = keep_last_n
        self.parquet_dir = "data/tickers"
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è Parquet —Ñ–∞–π–ª–æ–≤
        os.makedirs(self.parquet_dir, exist_ok=True)
        
        self._initialize_dataframe()
        self._last_dump_time = datetime.now()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–æ–Ω–æ–≤—É—é –∑–∞–¥–∞—á—É –¥–ª—è –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏—Ö –¥–∞–º–ø–æ–≤
        asyncio.create_task(self._periodic_dump_task())
    
    def _get_dataframe_columns(self) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É DataFrame –¥–ª—è —Ç–∏–∫–µ—Ä–æ–≤"""
        return [
            'symbol', 'timestamp', 'last_price', 'bid_price', 'ask_price',
            'volume', 'high', 'low', 'open', 'close', 'change', 'change_percent',
            'created_at'
        ]
    
    def _get_id_column(self) -> str:
        """ID –∫–æ–ª–æ–Ω–∫–∞ –¥–ª—è —Ç–∏–∫–µ—Ä–æ–≤ (—Å–æ—Å—Ç–∞–≤–Ω–æ–π –∫–ª—é—á symbol + timestamp)"""
        return 'timestamp'
    
    def _optimize_dataframe_dtypes(self):
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏"""
        if not self.df.empty:
            # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            self.df['symbol'] = self.df['symbol'].astype('category')
            self.df['timestamp'] = self.df['timestamp'].astype('int64')
            self.df['last_price'] = self.df['last_price'].astype('float64')
            self.df['bid_price'] = self.df['bid_price'].astype('float64')
            self.df['ask_price'] = self.df['ask_price'].astype('float64')
            self.df['volume'] = self.df['volume'].astype('float64')
    
    def _entity_to_dict(self, ticker: Ticker) -> Dict[str, Any]:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ Ticker –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è DataFrame"""
        return {
            'symbol': ticker.symbol,
            'timestamp': ticker.timestamp,
            'last_price': float(ticker.last) if ticker.last else 0.0,
            'bid_price': float(ticker.bid) if ticker.bid else 0.0,
            'ask_price': float(ticker.ask) if ticker.ask else 0.0,
            'volume': float(ticker.baseVolume) if ticker.baseVolume else 0.0,
            'high': float(ticker.high) if ticker.high else 0.0,
            'low': float(ticker.low) if ticker.low else 0.0,
            'open': float(ticker.open) if ticker.open else 0.0,
            'close': float(ticker.close) if ticker.close else 0.0,
            'change': float(ticker.change) if ticker.change else 0.0,
            'change_percent': float(ticker.percentage) if ticker.percentage else 0.0,
            'created_at': datetime.now()
        }
    
    def _dict_to_entity(self, data: Dict[str, Any]) -> Ticker:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è –∏–∑ DataFrame –≤ Ticker"""
        # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–π ticker –æ–±—ä–µ–∫—Ç
        ticker = Ticker(
            symbol=data['symbol'],
            timestamp=data['timestamp']
        )
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø–æ–ª—è
        ticker.last = data['last_price']
        ticker.bid = data['bid_price']
        ticker.ask = data['ask_price']
        ticker.baseVolume = data['volume']
        ticker.high = data['high']
        ticker.low = data['low']
        ticker.open = data['open']
        ticker.close = data['close']
        ticker.change = data['change']
        ticker.percentage = data['change_percent']
        
        return ticker
    
    def save(self, ticker: Ticker) -> None:
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–∏–∫–µ—Ä–∞ –≤ –ø–∞–º—è—Ç—å (–º–≥–Ω–æ–≤–µ–Ω–Ω–æ) + –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥–∞–º–ø
        """
        ticker_data = self._entity_to_dict(ticker)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ DataFrame
        if self.df.empty:
            self.df = pd.DataFrame([ticker_data])
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º pd.DataFrame.loc –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è FutureWarning —Å pd.concat
            new_index = len(self.df)
            self.df.loc[new_index] = ticker_data
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –¥–∞–º–ø–∞
        if len(self.df) >= self.batch_size:
            asyncio.create_task(self._dump_to_parquet())
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if len(self.df) > self.keep_last_n:
            self._clear_old_data()
    
    def get_by_id(self, ticker_id: int) -> Optional[Ticker]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ç–∏–∫–µ—Ä –ø–æ timestamp"""
        mask = self.df['timestamp'] == ticker_id
        if not mask.any():
            return None
        
        row = self.df[mask].iloc[-1]  # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –µ—Å–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ
        return self._dict_to_entity(row.to_dict())
    
    def get_all(self) -> List[Ticker]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö —Ç–∏–∫–µ—Ä–æ–≤ –∏–∑ DataFrame"""
        return [self._dict_to_entity(row.to_dict()) for _, row in self.df.iterrows()]
    
    def get_latest_ticker(self, symbol: str) -> Optional[Ticker]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ç–∏–∫–µ—Ä –ø–æ —Å–∏–º–≤–æ–ª—É"""
        symbol_mask = self.df['symbol'] == symbol
        if not symbol_mask.any():
            return None
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ timestamp –∏ –±–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π
        symbol_df = self.df[symbol_mask].sort_values('timestamp')
        latest_row = symbol_df.iloc[-1]
        
        return self._dict_to_entity(latest_row.to_dict())
    
    def get_price_history(self, symbol: str, limit: int = 100) -> List[float]:
        """–ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —Ü–µ–Ω"""
        symbol_mask = self.df['symbol'] == symbol
        if not symbol_mask.any():
            return []
        
        symbol_df = self.df[symbol_mask].sort_values('timestamp').tail(limit)
        return symbol_df['last_price'].tolist()
    
    def get_tickers_by_symbol(self, symbol: str, limit: int = 1000) -> List[Ticker]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ç–∏–∫–µ—Ä—ã –ø–æ —Å–∏–º–≤–æ–ª—É —Å –ª–∏–º–∏—Ç–æ–º"""
        symbol_mask = self.df['symbol'] == symbol
        if not symbol_mask.any():
            return []
        
        symbol_df = self.df[symbol_mask].sort_values('timestamp').tail(limit)
        return [self._dict_to_entity(row.to_dict()) for _, row in symbol_df.iterrows()]
    
    def get_volume_history(self, symbol: str, limit: int = 100) -> List[float]:
        """–ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –æ–±—ä–µ–º–æ–≤"""
        symbol_mask = self.df['symbol'] == symbol
        if not symbol_mask.any():
            return []
        
        symbol_df = self.df[symbol_mask].sort_values('timestamp').tail(limit)
        return symbol_df['volume'].tolist()
    
    def get_last_n(self, n: int) -> List[Ticker]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –∑–∞–ø–∏—Å–µ–π"""
        last_df = self.df.sort_values('timestamp').tail(n)
        return [self._dict_to_entity(row.to_dict()) for _, row in last_df.iterrows()]
    
    def get_by_time_range(self, start_time: datetime, end_time: datetime) -> List[Ticker]:
        """–ü–æ–ª—É—á–∏—Ç—å –∑–∞–ø–∏—Å–∏ –∑–∞ –ø–µ—Ä–∏–æ–¥ –≤—Ä–µ–º–µ–Ω–∏"""
        start_ts = int(start_time.timestamp() * 1000)
        end_ts = int(end_time.timestamp() * 1000)
        
        time_mask = (self.df['timestamp'] >= start_ts) & (self.df['timestamp'] <= end_ts)
        time_df = self.df[time_mask].sort_values('timestamp')
        
        return [self._dict_to_entity(row.to_dict()) for _, row in time_df.iterrows()]
    
    async def dump_to_persistent(self, batch_size: int = 10000) -> int:
        """–°–±—Ä–æ—Å –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ Parquet —Ñ–∞–π–ª—ã"""
        return await self._dump_to_parquet()
    
    def clear_old_data(self, keep_last_n: int = 100000) -> int:
        """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ø–∞–º—è—Ç–∏"""
        return self._clear_old_data(keep_last_n)
    
    def get_memory_usage_mb(self) -> float:
        """–ü–æ–ª—É—á–∏—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –≤ –ú–ë"""
        if self.df.empty:
            return 0.0
        memory_usage = self.df.memory_usage(deep=True).sum()
        return memory_usage / (1024 * 1024)
    
    def delete_by_id(self, ticker_id: int) -> bool:
        """–£–¥–∞–ª–∏—Ç—å —Ç–∏–∫–µ—Ä –ø–æ timestamp"""
        mask = self.df['timestamp'] == ticker_id
        if mask.any():
            self.df = self.df[~mask].reset_index(drop=True)
            return True
        return False
    
    async def _dump_to_parquet(self) -> int:
        """–°–±—Ä–æ—Å –¥–∞–Ω–Ω—ã—Ö –≤ Parquet —Ñ–∞–π–ª"""
        if self.df.empty:
            return 0
        
        try:
            # –°–æ–∑–¥–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞ —Å —Ç–µ–∫—É—â–µ–π –¥–∞—Ç–æ–π
            filename = f"tickers_{datetime.now().strftime('%Y%m%d_%H%M%S')}.parquet"
            filepath = os.path.join(self.parquet_dir, filename)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Parquet
            self.df.to_parquet(filepath, compression='snappy', index=False)
            
            dumped_count = len(self.df)
            logger.info(f"‚úÖ Dumped {dumped_count} tickers to {filepath}")
            
            # –û—á–∏—â–∞–µ–º DataFrame –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –¥–∞–º–ø–∞
            self.df = pd.DataFrame(columns=self._get_dataframe_columns())
            self._optimize_dataframe_dtypes()
            
            self._last_dump_time = datetime.now()
            return dumped_count
            
        except Exception as e:
            logger.error(f"‚ùå Error dumping tickers to Parquet: {e}")
            return 0
    
    def _clear_old_data(self, keep_last_n: int = None) -> int:
        """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ø–∞–º—è—Ç–∏"""
        if keep_last_n is None:
            keep_last_n = self.keep_last_n
        
        if len(self.df) <= keep_last_n:
            return 0
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ timestamp –∏ –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –∑–∞–ø–∏—Å–µ–π
        self.df = self.df.sort_values('timestamp').tail(keep_last_n).reset_index(drop=True)
        
        removed_count = len(self.df) - keep_last_n
        logger.info(f"üßπ Cleared {removed_count} old tickers from memory")
        
        return removed_count
    
    async def _periodic_dump_task(self):
        """–§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –¥–ª—è –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏—Ö –¥–∞–º–ø–æ–≤"""
        while True:
            try:
                await asyncio.sleep(self.dump_interval_minutes * 60)  # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å–µ–∫—É–Ω–¥—ã
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–µ–Ω –ª–∏ –¥–∞–º–ø
                time_since_last_dump = datetime.now() - self._last_dump_time
                if time_since_last_dump.total_seconds() >= self.dump_interval_minutes * 60:
                    if not self.df.empty:
                        await self._dump_to_parquet()
                        
            except Exception as e:
                logger.error(f"‚ùå Error in periodic dump task: {e}")
                await asyncio.sleep(60)  # –ñ–¥–µ–º –º–∏–Ω—É—Ç—É –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–æ–º