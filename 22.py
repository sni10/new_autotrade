#!/usr/bin/env python3
"""
AutoTrade Code Collector
–°–æ–±–∏—Ä–∞–µ—Ç –≤–µ—Å—å –∫–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞ (–∫—Ä–æ–º–µ —Ç–µ—Å—Ç–æ–≤) –≤ –æ–¥–∏–Ω markdown —Ñ–∞–π–ª
"""

import os
import sys
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Set


class CodeCollector:
    """–ö–ª–∞—Å—Å –¥–ª—è —Å–±–æ—Ä–∫–∏ –≤—Å–µ–≥–æ –∫–æ–¥–∞ –ø—Ä–æ–µ–∫—Ç–∞ –≤ –µ–¥–∏–Ω—ã–π markdown —Ñ–∞–π–ª"""

    def __init__(self, project_path: str, output_file: str = None):
        self.project_path = Path(project_path)
        self.output_file = output_file or f"autotrade_complete_code_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"

        # –†–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è
        self.include_extensions = {
            '.py', '.json', '.yaml', '.yml', '.toml', '.cfg', '.ini',
            '.txt', '.md', '.rst', '.requirements'
        }

        # –ü–∞–ø–∫–∏ –∏ —Ñ–∞–π–ª—ã –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è
        self.exclude_dirs = {
            '__pycache__', '.git', '.gitignore', 'venv', 'env', '.env',
            'node_modules', '.pytest_cache', '.mypy_cache', '.tox',
            'build', 'dist', '*.egg-info', '.idea', '.vscode',
            'test', 'tests', 'testing',  # –ò—Å–∫–ª—é—á–∞–µ–º —Ç–µ—Å—Ç—ã
            'docker', 'Docker', 'dockerfile', 'Dockerfile',  # Docker
            'docs', 'documentation', 'doc',  # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
            'assets', 'static', 'media', 'images', 'img',  # –ú–µ–¥–∏–∞
            'logs', 'log', 'tmp', 'temp', 'cache',  # –í—Ä–µ–º–µ–Ω–Ω—ã–µ
            'backup', 'backups', 'old', 'archive',  # –ë—ç–∫–∞–ø—ã
            'vendor', 'lib', 'libs', 'external',  # –í–Ω–µ—à–Ω–∏–µ –ª–∏–±—ã
            'migrations', 'seeds', 'fixtures',  # –ë–î —Ñ–∞–π–ª—ã
            'coverage', 'htmlcov', '.coverage',  # –ü–æ–∫—Ä—ã—Ç–∏–µ –∫–æ–¥–∞
            'scripts', 'tools', 'utils', 'bin',  # –£—Ç–∏–ª–∏—Ç—ã
            'config', 'configs', 'settings',  # –ö–æ–Ω—Ñ–∏–≥–∏ (–æ—Ç–¥–µ–ª—å–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–µ–º)
            'project_management', 'pm', 'roadmap'  # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–æ–º
        }

        self.exclude_files = {
            '.gitignore', '.dockerignore', '.DS_Store', 'Thumbs.db',
            '*.pyc', '*.pyo', '*.pyd', '__pycache__', '*.so',
            '*.log', '*.tmp', '*.temp', '*.swp', '*.swo'
        }

        # –ö–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã (–ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É, –Ω–æ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ)
        self.sensitive_files = {
            'config.json', 'secrets.json', 'credentials.json',
            '.env', '.env.local', '.env.production',
            'id_ed25519.pem', 'test-prv-key.pem'
        }

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            'total_files': 0,
            'processed_files': 0,
            'skipped_files': 0,
            'total_lines': 0,
            'total_size': 0
        }

    def should_exclude_dir(self, dir_name: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –∏—Å–∫–ª—é—á–∏—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é"""
        dir_lower = dir_name.lower()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        if dir_lower in self.exclude_dirs:
            return True

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–∞—Å—Ç–∏—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –¥–ª—è —Ç–µ—Å—Ç–æ–≤
        test_keywords = ['test', 'testing', 'spec', 'specs']
        if any(keyword in dir_lower for keyword in test_keywords):
            return True

        # –°–∫—Ä—ã—Ç—ã–µ –ø–∞–ø–∫–∏ (–Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å —Ç–æ—á–∫–∏)
        if dir_name.startswith('.') and dir_name not in {'.github', '.gitlab'}:
            return True

        return False

    def should_exclude_file(self, file_path: Path) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –∏—Å–∫–ª—é—á–∏—Ç—å —Ñ–∞–π–ª"""
        file_name = file_path.name.lower()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
        if file_path.suffix not in self.include_extensions:
            return True

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–º—è —Ñ–∞–π–ª–∞
        if any(pattern in file_name for pattern in self.exclude_files):
            return True

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã
        test_keywords = ['test_', '_test', 'test.py', 'tests.py', 'spec_', '_spec']
        if any(keyword in file_name for keyword in test_keywords):
            return True

        return False

    def is_sensitive_file(self, file_path: Path) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–º"""
        return file_path.name in self.sensitive_files

    def get_file_tree(self) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–µ—Ä–µ–≤–æ —Ñ–∞–π–ª–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞"""
        tree_lines = []

        def add_tree_node(path: Path, prefix: str = "", is_last: bool = True):
            if self.should_exclude_dir(path.name) and path.is_dir():
                return

            connector = "‚îî‚îÄ‚îÄ " if is_last else "‚îú‚îÄ‚îÄ "
            tree_lines.append(f"{prefix}{connector}{path.name}")

            if path.is_dir():
                try:
                    children = sorted([p for p in path.iterdir()
                                       if not self.should_exclude_dir(p.name) or not p.is_dir()])
                    for i, child in enumerate(children):
                        child_is_last = i == len(children) - 1
                        extension = "    " if is_last else "‚îÇ   "
                        add_tree_node(child, prefix + extension, child_is_last)
                except PermissionError:
                    pass

        tree_lines.append(f"üìÅ {self.project_path.name}/")
        try:
            children = sorted([p for p in self.project_path.iterdir()
                               if not self.should_exclude_dir(p.name) or not p.is_dir()])
            for i, child in enumerate(children):
                is_last = i == len(children) - 1
                add_tree_node(child, "", is_last)
        except PermissionError:
            tree_lines.append("‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏")

        return tree_lines

    def collect_files(self) -> Dict[str, List[Path]]:
        """–°–æ–±–∏—Ä–∞–µ—Ç –≤—Å–µ —Ñ–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞, –≥—Ä—É–ø–ø–∏—Ä—É—è –ø–æ —Ç–∏–ø–∞–º"""
        files_by_type = {}

        def scan_directory(directory: Path):
            try:
                for item in directory.iterdir():
                    if item.is_dir():
                        if not self.should_exclude_dir(item.name):
                            scan_directory(item)
                    elif item.is_file():
                        self.stats['total_files'] += 1

                        if not self.should_exclude_file(item):
                            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é
                            ext = item.suffix or 'no_extension'
                            if ext not in files_by_type:
                                files_by_type[ext] = []
                            files_by_type[ext].append(item)
                            self.stats['processed_files'] += 1
                        else:
                            self.stats['skipped_files'] += 1
            except PermissionError:
                print(f"‚ö†Ô∏è  –ù–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {directory}")

        scan_directory(self.project_path)
        return files_by_type

    def read_file_safely(self, file_path: Path) -> str:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ —á–∏—Ç–∞–µ—Ç —Ñ–∞–π–ª —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∫–æ–¥–∏—Ä–æ–≤–æ–∫"""
        encodings = ['utf-8', 'utf-8-sig', 'cp1251', 'latin1']

        for encoding in encodings:
            try:
                with open(file_path, 'r', encoding=encoding) as f:
                    content = f.read()
                    self.stats['total_lines'] += len(content.splitlines())
                    self.stats['total_size'] += len(content.encode('utf-8'))
                    return content
            except (UnicodeDecodeError, UnicodeError):
                continue
            except Exception as e:
                return f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}"

        return "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª —Å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–º–∏ –∫–æ–¥–∏—Ä–æ–≤–∫–∞–º–∏"

    def generate_markdown(self, files_by_type: Dict[str, List[Path]]) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç markdown —Ñ–∞–π–ª —Å –∫–æ–¥–æ–º"""
        md_content = []

        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        md_content.extend([
            f"# ü§ñ AutoTrade - –ü–æ–ª–Ω—ã–π –∫–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞",
            f"",
            f"**–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  ",
            f"**–ü—Ä–æ–µ–∫—Ç:** {self.project_path}  ",
            f"**–§–∞–π–ª–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ:** {self.stats['processed_files']} –∏–∑ {self.stats['total_files']}  ",
            f"**–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä:** {self.stats['total_size']:,} –±–∞–π—Ç  ",
            f"**–°—Ç—Ä–æ–∫ –∫–æ–¥–∞:** {self.stats['total_lines']:,}  ",
            f"",
            "---",
            ""
        ])

        # –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ
        md_content.extend([
            "## üìë –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ",
            "",
            "- [üå≥ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞](#-—Å—Ç—Ä—É–∫—Ç—É—Ä–∞-–ø—Ä–æ–µ–∫—Ç–∞)",
            "- [üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ñ–∞–π–ª–æ–≤](#-—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞-—Ñ–∞–π–ª–æ–≤)"
        ])

        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å–µ–∫—Ü–∏–∏
        for ext in sorted(files_by_type.keys()):
            if ext == '.py':
                md_content.append("- [üêç Python —Ñ–∞–π–ª—ã](#-python-—Ñ–∞–π–ª—ã)")
            elif ext == '.json':
                md_content.append("- [‚öôÔ∏è JSON –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏](#Ô∏è-json-–∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏)")
            elif ext in ['.md', '.rst']:
                md_content.append("- [üìù –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è](#-–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è)")
            else:
                section_name = f"{ext.upper()[1:]} —Ñ–∞–π–ª—ã" if ext.startswith('.') else f"{ext} —Ñ–∞–π–ª—ã"
                anchor = section_name.lower().replace(' ', '-').replace('.', '')
                md_content.append(f"- [üìÑ {section_name}](#{anchor})")

        md_content.extend(["", "---", ""])

        # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞
        md_content.extend([
            "## üå≥ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞",
            "",
            "```",
            *self.get_file_tree(),
            "```",
            ""
        ])

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        md_content.extend([
            "## üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ñ–∞–π–ª–æ–≤",
            "",
            f"| –ú–µ—Ç—Ä–∏–∫–∞ | –ó–Ω–∞—á–µ–Ω–∏–µ |",
            f"|---------|----------|",
            f"| –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ –Ω–∞–π–¥–µ–Ω–æ | {self.stats['total_files']} |",
            f"| –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤ | {self.stats['processed_files']} |",
            f"| –ü—Ä–æ–ø—É—â–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ | {self.stats['skipped_files']} |",
            f"| –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ | {self.stats['total_lines']:,} |",
            f"| –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä (–±–∞–π—Ç) | {self.stats['total_size']:,} |",
            ""
        ])

        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ —Ñ–∞–π–ª–æ–≤ –ø–æ —Ç–∏–ø–∞–º
        type_stats = {}
        for ext, files in files_by_type.items():
            type_stats[ext] = len(files)

        if type_stats:
            md_content.extend([
                "### –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º —Ñ–∞–π–ª–æ–≤:",
                "",
                "| –¢–∏–ø | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ |",
                "|-----|------------|"
            ])

            for ext in sorted(type_stats.keys()):
                ext_name = ext if ext != 'no_extension' else '–±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è'
                md_content.append(f"| {ext_name} | {type_stats[ext]} |")

            md_content.append("")

        # –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–æ–≤ –ø–æ —Ç–∏–ø–∞–º
        for ext in sorted(files_by_type.keys()):
            files = sorted(files_by_type[ext], key=lambda x: x.relative_to(self.project_path))

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å–µ–∫—Ü–∏–∏
            if ext == '.py':
                section_title = "üêç Python —Ñ–∞–π–ª—ã"
                lang = "python"
            elif ext == '.json':
                section_title = "‚öôÔ∏è JSON –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"
                lang = "json"
            elif ext in ['.yaml', '.yml']:
                section_title = "üìã YAML —Ñ–∞–π–ª—ã"
                lang = "yaml"
            elif ext == '.md':
                section_title = "üìù Markdown –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è"
                lang = "markdown"
            elif ext == '.rst':
                section_title = "üìù RestructuredText –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è"
                lang = "rst"
            elif ext == '.toml':
                section_title = "‚öôÔ∏è TOML –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"
                lang = "toml"
            else:
                section_title = f"üìÑ {ext.upper()[1:]} —Ñ–∞–π–ª—ã" if ext.startswith('.') else f"üìÑ {ext} —Ñ–∞–π–ª—ã"
                lang = "text"

            md_content.extend([
                f"## {section_title}",
                ""
            ])

            for file_path in files:
                relative_path = file_path.relative_to(self.project_path)

                md_content.extend([
                    f"### üìÑ `{relative_path}`",
                    ""
                ])

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π –ª–∏ —Ñ–∞–π–ª
                if self.is_sensitive_file(file_path):
                    md_content.extend([
                        "```text",
                        "üîí –ö–û–ù–§–ò–î–ï–ù–¶–ò–ê–õ–¨–ù–´–ô –§–ê–ô–õ - –°–û–î–ï–†–ñ–ò–ú–û–ï –°–ö–†–´–¢–û",
                        f"–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_path.stat().st_size} –±–∞–π—Ç",
                        f"–ü–æ—Å–ª–µ–¥–Ω–µ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ: {datetime.fromtimestamp(file_path.stat().st_mtime)}",
                        "```",
                        ""
                    ])
                else:
                    content = self.read_file_safely(file_path)

                    md_content.extend([
                        f"```{lang}",
                        content,
                        "```",
                        ""
                    ])

        return "\n".join(md_content)

    def run(self) -> bool:
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å —Å–±–æ—Ä–∫–∏"""
        print(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º —Å–±–æ—Ä–∫—É –∫–æ–¥–∞ –ø—Ä–æ–µ–∫—Ç–∞: {self.project_path}")

        if not self.project_path.exists():
            print(f"‚ùå –ü—Ä–æ–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {self.project_path}")
            return False

        print("üìÅ –°–∫–∞–Ω–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã...")
        files_by_type = self.collect_files()

        if not files_by_type:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return False

        print(f"üìù –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º markdown —Ñ–∞–π–ª: {self.output_file}")
        markdown_content = self.generate_markdown(files_by_type)

        try:
            with open(self.output_file, 'w', encoding='utf-8') as f:
                f.write(markdown_content)

            print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω —Ñ–∞–π–ª: {self.output_file}")
            print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
            print(f"   - –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {self.stats['processed_files']}")
            print(f"   - –ü—Ä–æ–ø—É—â–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {self.stats['skipped_files']}")
            print(f"   - –°—Ç—Ä–æ–∫ –∫–æ–¥–∞: {self.stats['total_lines']:,}")
            print(f"   - –†–∞–∑–º–µ—Ä: {self.stats['total_size']:,} –±–∞–π—Ç")

            return True

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ —Ñ–∞–π–ª–∞: {e}")
            return False


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    # –ó–∞—Ö–∞—Ä–¥–∫–æ–∂–µ–Ω–Ω—ã–π –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
    project_path = r"F:\HOME\new_autotrade"
    output_file = r"/autotrade_complete_code.md"

    print(f"üéØ –°–æ–±–∏—Ä–∞–µ–º –∫–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞: {project_path}")
    print(f"üìù –í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {output_file}")

    collector = CodeCollector(project_path, output_file)

    success = collector.run()

    if success:
        print(f"\nüéâ –ì–û–¢–û–í–û! –§–∞–π–ª —Å–æ–∑–¥–∞–Ω: {output_file}")
    else:
        print(f"\nüí• –û–®–ò–ë–ö–ê! –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ñ–∞–π–ª")

    input("\n–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –≤—ã—Ö–æ–¥–∞...")
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()